{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 今天是2020年08月16日，今天世界上又多了一名AI工程师 :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复现课堂代码\n",
    "\n",
    "在本部分，你需要参照我们给大家的GitHub地址里边的课堂代码，结合课堂内容，复现内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: （1）智慧交通系统--短时交通流量预测调度交通 （2）人脸识别身份验证、支付 （3）医学影像病理检测、三维重构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 从Github上可获取到很多不同项目的代码，jupyter notebook用于讲解代码或代码调试，pycharm用于写一些比较大的项目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:概率模型是一个概率分布函数或密度函数的集合，可分为参数模型,无参数和半参数模型。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:分类聚类问题、朴素贝叶斯模型、推荐系统等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:困难之处：模糊性、不确定性和不完整行性，我们可以通过使用概率模型，寻找出最可能表达正确的句子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:语言模型是用来计算一个句子的概率的模型，也就是判断一句话是否是合理的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:机器翻译、语音-文本转换、问答系统。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:1-gram模型是假设句子中所有词之间都是相互独立的，即每个词出现的概率与其他词都无关，考虑单个词出现的概率，句子s出现的概率为$$p(s)=p(w_{1})*p(w_{2})\\dots*p(w_{n})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:优点：简单、计算得比较快，缺点：对于“I love you”和“Love I you”这样颠倒语序的句子，它们的1-gram概率是相同的，无法区分，判断句子准确率比较低。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:2-gram模型是假设句子中每个词出现的概率和它的前1个词相关（马尔科夫性），即考虑2个词组成的词组出现的概率，整个句子s出现的概率为$$p(s)=p(w_{1})*p(w_{2}|w_{1})*p(w_{3}|w_{2})\\dots*p(w_{n}|w_{n-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1569578233461&di=4adfa7597fb380e7cc0e67190bbd7605&imgtype=0&src=http%3A%2F%2Fs1.sinaimg.cn%2Flarge%2F006eYYfyzy76cmpG3Yb1f)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from operator import add, mul\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily_life = \"\"\"\n",
    "sentence = 人物 标点符号 位置 天气状况 标点符号 人称 行为 结尾语气词 标点符号\n",
    "人物 = 兄弟 | 哥哥 | 弟弟\n",
    "标点符号 = ， | 。| ？\n",
    "位置 = 时间 | 时间 空间\n",
    "时间 = 今天 | 现在\n",
    "空间 = 外边 | 外面\n",
    "天气状况 = 天气很好 | 下雨了 | 天气晴朗 | 很凉爽\n",
    "人称 = 我们 | 咱们\n",
    "行为 = 动作 事件\n",
    "动作 = 打 | 逛 | 去 | 看\n",
    "事件 = 篮球 | 羽毛球 | 跑步 |电影 \n",
    "结尾语气词 = 吧 | 吗\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**： 是否提出了和课程上区别较大的语法结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie = \"\"\"\n",
    "sentence = 电影名称 判断词 国籍 标点符号 人物 表达观点 标点符号 连接词 行为 标点符号\n",
    "电影名称 = 《三傻大闹宝莱坞》 | 《中国机长》 | 《流浪地球》 | 《肖申克的救赎》 | 《异形》 | 《后天》 | 《2012》\n",
    "判断词 = 是 | 不是\n",
    "国籍 = 美国电影 | 中国电影 | 印度电影\n",
    "人物 = 人称 | 人称 人称关系名称\n",
    "人称 = 你 | 我 | 他 | 她\n",
    "人称关系名称 = 父母 | 朋友 | 女朋友 | 男朋友 | 哥哥 | 姐姐 | 同学\n",
    "表达观点 = 情感倾向 指代电影词 | 程度 情感倾向 指代电影词\n",
    "情感倾向 = 喜欢 | 不喜欢 | 讨厌\n",
    "程度 = 非常 | 很\n",
    "指代电影词 = 它 | 这部电影\n",
    "连接词 = 但是 | 所以\n",
    "行为 = 动作 | 动作 次数\n",
    "动作 = 看过了 | 没有看过\n",
    "次数 = 1遍 | 2遍 | 3遍 | 很多遍\n",
    "标点符号 = ，| 。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**：是否和上一个语法区别比较大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_grammar(grammar_str, split='=>', line_split='\\n'):\n",
    "    grammar = {}\n",
    "    for line in grammar_str.split(line_split):\n",
    "        if not line.strip(): continue\n",
    "        exp, stmt = line.split(split)\n",
    "        grammar[exp.strip()] = [s.split() for s in stmt.split('|')]\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = create_grammar(movie, split='=')\n",
    "daily_life = create_grammar(daily_life, split='=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "choice = random.choice\n",
    "def generate(gram, target):\n",
    "    if target not in gram: return target \n",
    "    \n",
    "    expaned = [generate(gram, t) for t in choice(gram[target])]\n",
    "    return ''.join([e if e != '/n' else '\\n' for e in expaned if e != 'null'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'《后天》是印度电影，我非常讨厌它，但是没有看过，'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(movie, 'sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'弟弟，外边天气很好。我们打跑步吗？'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(daily_life, 'sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_n(gram, target, n):\n",
    "    sentence_list = []\n",
    "    for i in range(n):\n",
    "        if target not in gram: return target \n",
    "    \n",
    "        expaned = [generate(gram, t) for t in choice(gram[target])]  \n",
    "        sentence = ''.join([e if e != '/n' else '\\n' for e in expaned if e != 'null']) \n",
    "        sentence_list.append(sentence)\n",
    "    return sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['《流浪地球》不是中国电影，我非常喜欢这部电影，但是看过了。',\n",
       " '《异形》是中国电影。我姐姐不喜欢这部电影。所以没有看过很多遍。',\n",
       " '《三傻大闹宝莱坞》是印度电影。他父母非常喜欢它。但是没有看过3遍，',\n",
       " '《后天》不是美国电影。她喜欢它，但是看过了很多遍。',\n",
       " '《肖申克的救赎》是美国电影，她讨厌这部电影，所以没有看过。',\n",
       " '《2012》不是中国电影。你讨厌它。但是看过了。',\n",
       " '《后天》是中国电影，我喜欢这部电影。所以看过了，',\n",
       " '《异形》是美国电影，她非常不喜欢这部电影，所以没有看过，',\n",
       " '《中国机长》是美国电影。我男朋友非常不喜欢这部电影。所以没有看过很多遍，',\n",
       " '《异形》是中国电影。我非常喜欢它。但是看过了。',\n",
       " '《2012》不是中国电影。她女朋友不喜欢这部电影。但是看过了1遍，',\n",
       " '《异形》是中国电影。他不喜欢这部电影，所以没有看过。',\n",
       " '《三傻大闹宝莱坞》不是印度电影。他姐姐喜欢它。所以没有看过1遍。',\n",
       " '《后天》是美国电影，你父母非常不喜欢它，所以没有看过。',\n",
       " '《肖申克的救赎》是印度电影，你很喜欢这部电影。所以看过了3遍。',\n",
       " '《三傻大闹宝莱坞》是美国电影，你很不喜欢它，但是看过了。',\n",
       " '《中国机长》不是中国电影，我不喜欢这部电影，但是看过了，',\n",
       " '《流浪地球》是美国电影，你父母很不喜欢这部电影。但是看过了，',\n",
       " '《2012》是印度电影。你哥哥非常讨厌它，但是看过了3遍，',\n",
       " '《肖申克的救赎》不是中国电影。你哥哥很喜欢它，所以看过了。']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_n(movie, 'sentence', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['弟弟，外面天气晴朗。我们去电影吧。',\n",
       " '弟弟。外边天气很好，我们逛电影吗？',\n",
       " '哥哥？外边天气晴朗。我们逛篮球吗？',\n",
       " '哥哥？天气很好，我们逛羽毛球吗？',\n",
       " '兄弟，外边很凉爽。我们逛羽毛球吗。',\n",
       " '哥哥，下雨了，咱们逛篮球吧？',\n",
       " '弟弟。外面很凉爽，咱们看电影吗，',\n",
       " '兄弟。天气晴朗，咱们打篮球吗，',\n",
       " '哥哥，外边下雨了。咱们去篮球吧？',\n",
       " '弟弟，天气晴朗？咱们逛篮球吧？',\n",
       " '哥哥？外边天气很好，我们打羽毛球吗，',\n",
       " '哥哥，外边天气晴朗。我们看电影吧？',\n",
       " '弟弟？外面天气很好？我们看篮球吗，',\n",
       " '弟弟，天气晴朗，我们去篮球吗。',\n",
       " '哥哥？很凉爽。我们去羽毛球吗。',\n",
       " '弟弟。外边天气晴朗？咱们看电影吗。',\n",
       " '兄弟？外边很凉爽。我们看羽毛球吗？',\n",
       " '弟弟，外边天气晴朗。我们去跑步吗。',\n",
       " '兄弟，外边天气晴朗？我们打羽毛球吧？',\n",
       " '弟弟？天气晴朗。我们打羽毛球吗。']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_n(daily_life, 'sentence', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**; 运行代码，观察是否能够生成多个句子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "吴京 意淫 到 了 脑残 的 地步 ， 看 了 恶心 想 吐\n",
      "首映礼 看 的 。 太 恐怖 了 这个 电影 ， 不讲道理 的 ， 完全 就是 吴京 在 实现 他 这个 小 粉红 的 英雄 梦 。 各种 装备 轮番 上场 ， 视 物理 逻辑 于 不顾 ， 不得不 说 有钱 真 好 ， 随意 胡闹\n",
      "吴京 的 炒作 水平 不输 冯小刚 ， 但小刚 至少 不会 用 主旋律 来 炒作 … 吴京 让 人 看 了 不 舒服 ， 为了 主旋律 而 主旋律 ， 为了 煽情 而 煽情 ， 让 人 觉得 他 是 个 大 做作 、 大 谎言 家 。 （ 7.29 更新 ） 片子 整体 不如 湄公河 行动 ， 1 . 整体 不够 流畅 ， 编剧 有毒 ， 台词 尴尬 ； 2 . 刻意 做作 的 主旋律 煽情 显得 如此 不合时宜 而 又 多余 。\n",
      "凭良心说 ， 好 看到 不像 《 战狼 1 》 的 续集 ， 完虐 《 湄公河 行动 》 。\n",
      "中二得 很\n",
      "“ 犯 我 中华 者 ， 虽远必 诛 ” ， 吴京 比 这句 话 还要 意淫 一百倍 。\n",
      "脑子 是 个 好 东西 ， 希望 编剧 们 都 能 有 。\n",
      "三星 半 ， 实打实 的 7 分 。 第一集 在 爱国 主旋律 内部 做 着 各种 置换 与 较劲 ， 但 第二集 才 真正 显露 吴京 的 野心 ， 他 终于 抛弃 李忠志 了 ， 新增 外来 班底 让 硬件 实力 有 机会 和 国际 接轨 ， 开篇 水下 长镜头 和 诸如 铁丝网 拦截 RPG 弹头 的 细节 设计 都 让 国产 动作片 重新 封顶 ， 在 理念 上 ， 它 甚至 做到 《 绣春刀 2 》 最 想做到 的 那 部分 。\n",
      "开篇 长镜头 惊险 大气 引人入胜   结合 了 水平 不俗 的 快 剪下 实打实 的 真刀真枪   让 人 不禁 热血沸腾   特别 弹簧床 架 挡 炸弹   空手 接 碎玻璃   弹匣 割喉 等 帅 得 飞起 ！ 就算 前半段 铺垫 节奏 散漫 主角 光环 开太大 等 也 不怕   作为 一个 中国 人   两个 小时 弥漫着 中国 强大 得 不可 侵犯 的 氛围   还是 让 那颗 民族 自豪 心 砰砰 砰 跳个 不停 。\n",
      "15 / 100 吴京 的 冷峰 在 这部 里 即 像 成龙 ， 又 像杰 森斯坦 森 ， 但 体制 外 的 同 类型 电影 ， 主角 总是 代表 个人 ， 无能 的 政府 需要 求助于 这些 英雄 才能 解决 难题 ， 体现 的 是 个人 的 价值 ， 所以 主旋律 照抄 这种 模式 实际上 是 有 问题 的 。 我们 以前 嘲笑 个人 英雄主义 ， 却 没想到 捆绑 爱国主义 的 全能 战士 更加 难以 下咽 。\n",
      "犯 我 中华 者 虽远必 诛 ， 是 有 多 无脑 才 信 这句 话 。\n",
      "这部 戏 让 人 看 的 热血沸腾 ， 对 吴京路 转粉 ， 最后 的 彩蛋 ， 让 我们 没有 理由 不 期待 下 一部 。\n",
      "假 嗨 ， 特别 恶心 的 电影 。\n",
      "有 几处 情节 设置 过于 尴尬 ， 彰显 国家 自豪感 的 部分 稍显 突兀 。\n",
      "就是 一部 爽片 ， 打戏 挺燃 ， 但是 故事 一般 。 达康 书记 不 合适 这个 角色 ， 赵 东来 倒 是 很 合适 。 张瀚 太太 太违 和 了 ， 分 分钟 穿越 回 偶像剧 。\n",
      "赵 东来 ： 达康 书记 ， 我们 接到 在 非洲 卧底 的 冷锋 报告 ， 丁义珍 现在 非洲 ， 我们 请求 抓捕 。 李达康 ： 东来 ， 这件 事先 不要 声张 ， 特别 是 别 让 省厅 知道 ， 就 你 和 我 一起 去 非洲 ， 加上 冷锋 同志 ， 三人 逮捕 丁义珍 。 这次 行 就 叫 战狼 2 吧\n",
      "下 一部 拍 喜剧 吧 ， 整个 片子 真 感觉 挺 搞笑 的\n",
      "《 战狼 2 》 里 吴京 这么 能 打 ， 他 打 得 过 徐晓冬 么 ？\n",
      "心往 一处 想 ， 劲往 一处 使 ， 就 能 实现 我们 的 梦想 。 看吧 ， 比 第一部 好太多 了 。 谢谢 美队 的 动作 指导 。\n",
      "这 都 能 火 。 是 我 没见识 ！\n",
      "开头 的 水下 长 对决 戏可算 华语 电影 的 顶尖 存在 ； 驱逐舰 、 导弹 和 坦克 在 商业片 里 这么 狂用 也 是 了 得 ； 镜头 运用 和 笑 点 插入 都 很 好莱坞 爆米花 ， 不功 不过 ； 从头 打到 尾 是 真 拼 ， 虽然 镜头 也 有略 乱 时 ； 因为 没 啥 期望值 ， 所以 被 吴京 的 野心 吓了一跳 ； 吴刚 、 于 谦和 丁海峰 老 三位 像 炖 烂熟 的 牛筋 ， 嚼 着 就 舒服 。\n",
      "很 用心 啊 吴京 导演 ， 小看 你 了 ， 确实 在 导演 上 下功夫 了 拉 片子 了 ， 知道 借鉴 是 好 的 。 至于 大家 比较 反感 的 小 粉红 情绪 我 觉得 那些 桥段 都 是 主旋律 必备 啊 是 稍微 有 一点 过 但 还 可以 接受 。 最好 的 地方 是 吴京 节奏 掌握 得 很 好 ， 知道 张弛 有度 ， 这点 很 难得 。\n",
      "犯 我 中华 者 虽远必 诛 ， 这句 话 一直 在 我 脑子里 回响\n",
      "片头 海里 那场 动作 戏看 完 就 呆 不 下去 了 ， 太假 太 做作 ， 提前 离场 。\n",
      "好看 ， 这部 戏 让 人 看 的 热血沸腾 ， 打戏 挺燃 的 ， 吴京 演技 棒呆 了\n",
      "符合 “ 有钱 了 续集 反而 拍 更 差 ” 这一 放之四海而皆准 的 规律 ， 场面 越做越 大 ， 然而 伴随 着 各种 动作 场面 和 特效 场面 的 升级 ， 这 一部 的 叙事 反而 变得 非常 凌乱 。 格局 颇 大 ， 想 拍成 《 黑鹰坠落 》 ， 结果 撑死 最多 也 只是 官方 主旋律 版 的 《 敢死队 》 。 吴京 确实 有 野心 ， 但论 自我 角色定位 能力 远 不 如同 是 动作 演员 出身 的 甄子丹 。\n",
      "说 喜欢 这部 片子 的 人 不是 装傻 就是 真傻 ， 要不是 真的 没有 别的 可 看 肯定 是 不会 选 这部 的 ， 直男癌 到 令人发指 ， 所有 剧情 走向 也 完全 是 九十年代 那套 照搬 ， 审美 这件 事儿 真 不是 一时半会儿 能 培养 出来 的 。\n",
      "整部 电影 延续 1 的 风格 ， 热血 。 场面 比 1 来 的 要 大 ， 打戏 动作 不错 ， 吴京 挺 适合 演 军人 的 ， 电影 之前 的 中国 梦 片段 他 都 念 的 劲儿 劲儿 的 。 整体 来说 还 不错 ， 不过 张翰太违 和 了 ， 一 出来 就 一股 雷阵雨 的 画风 。\n",
      "目瞪狗 呆 ！ 太 瘠薄 好看 了 ！ 中国 人牛 b 就是 硬道理 ！ 隔壁 建军 大爷 都 没 你们 爱国\n",
      "《 战狼 2 》 的 动作 场景 和 战斗 装备 全线 升级 ， 热血 的 打斗 动作 从头 打到 尾 。 《 战狼 2 》 游走 在 电影 审查 红线 的 边界 和 政治 安全 的 缝隙 ， 是 部 延续 了 第一部 极具 煽动 爱国 情绪 的 国产 动作 大片 。 如此 制作 精良 的 影片 ， 还 请 多来 一点 。\n",
      "电影 用 的 胶卷 挺差 的 ， 故事 过度 也 差 ， 地方 部队 还 没太多 展示 就 死去 ， 反正 各种 问题 。 但 就是 能 吸引 人 看 下去 ， 就 冲 这 ， 为什么 要 这么 鄙视 敢 想 敢 去 开拓 的 人 ， 不 允许 他们 再 去 拍 ， 直到 能 有 更好 的 人 ， 拍出 更 棒 的 更 出彩 的 电影 来 呢 ？\n",
      "火爆 的 场面 拍出 了 好莱坞 大片 的 感觉 ， 本片 必将 燃爆 暑期\n",
      "吴京 厉害 了 ， 身为 武打 演员 ， 能 拍 到 这么 高标准 的 大 场面 的 枪战 戏 ， 为 你 点赞 。 热血男儿 ， 荷尔蒙 爆发 ！\n",
      "能 给 0 星 么 ， 好 恶心 啊\n",
      "《 血战 钢锯 岭 》 中国 人 也 会 觉得 好看 ， 因为 它 歌颂 的 宗教 情怀 是 超越 政权 的 ； 但 当 你 只 想 歌颂 一个 政权 时 ， 很 明显 就 低 了 一个 层次 ， 甚至 充满 了 现实 乃至 投机 的 考量 ， 高下 立 见\n",
      "请问 吴京脑 残 ， 弹簧床 能 挡 火箭炮 吗 ？\n",
      "上 一部 是 傲气 雄鹰 ， 这 一部 是 第一 滴血 4 。 吴京 算是 国内 导演 对 类型 片 感觉 比较 准 的 ， 作为 动作片 钱 都 花 在 有效 地方 ， 整体 火爆 流畅 ， 有 大片 气魄 ， 创作 上 也 足够 真诚 。 人物 设计 也 都 不错 ， 连 张翰 都 很 可爱 了 。 如果 吴京 不 像 当年 甄子丹 那样 一时 膨胀 、 在 银幕 上 独占 聚光灯 ， 肯定 可以 走 得 更 远 。\n",
      "扪心自问 这种 电影 真 没法 评价 ， 全片 靠 动作 戏撑 完 ， 文戏 都 是 扯淡 ， 女主角 毫无 存在 的 必要 ， 故事 不 需要 逻辑 只要 主角 开挂 ， 但 牛 逼 之处 在于 全片 都 透露 着 极 强烈 的 爱国主义 光环 和 意识形态 枷锁 ， 在 祖国 面前 ， 一切 反动派 都 是 纸老虎 ， 所以 战狼 一个 人开 挂 团灭 一个 连 都 是 合情合理 的 ， 动作 戏 还 不错 ， 挺 用心 ， 两星 鼓励\n",
      "扪心自问 这种 电影 真 没法 评价 ， 全片 靠 动作 戏撑 完 ， 文戏 都 是 扯淡 ， 女主角 毫无 存在 的 必要 ， 故事 不 需要 逻辑 只要 主角 开挂 ， 但 牛 逼 之处 在于 全片 都 透露 着 极 强烈 的 爱国主义 光环 和 意识形态 枷锁 ， 在 祖国 面前 ， 一切 反动派 都 是 纸老虎 ， 所以 战狼 一个 人开 挂 团灭 一个 连 都 是 合情合理 的 ， 动作 戏 还 不错 ， 挺 用心 ， 两星 鼓励\n",
      "两星 给 打戏 ， 其他 一般般 ， 没 啥 看点 ， 还 有点 尴尬 ？\n",
      "太 尴尬 了 ！ ！ ！ ！ 手接 炸弹 ！ ！ 哈哈哈 ！ ！ ！ 从 张翰 出来 之后 ， 我 就 想 炸 了 他 ！ ！\n",
      "翻 了 一下 我 给 第一部 的 评价 是 四星 ， 当时 觉得 挺燃 的 ， 这部 其实 在 完成度 上 更 接近 好莱坞 的 制作 了 ， 每个 步骤 每个 人物 的 走向 都 很 顺滑 ， 没有 任何 出人意料 的 地方 。 只 给 三星 是因为 ， 看看 最近 现实 世界 的 一切 ， 抱歉 我 在 影院 里 燃 不 起来 ， 只是 觉得 一切 都 很 魔幻 ， 当然 开头 的 强拆 是 最 有 现实感 的 一幕 了 。\n",
      "太 喜欢 《 战狼 2 》 开场 6 分钟 长镜头 的 水下 搏斗 戏 了 ！ 从来 没有 在 其它 任何 一部 电影 里 看到 过 ， 因为 拍摄 难度 真的 不 一般 ， 同时 还 对 演员 有 各种 技能 方面 的 要求 。 看 完 片子 回来 搜 了 下 ， 被 吴京会 游泳 、 潜水 、 滑雪 、 开 飞机 、 开 坦克 、 射击 等 各项 技能 ， 还 特意 去 特种部队 当过 18 个 月 兵 … 真的 很 佩服 这样 的 电影 人 ！\n",
      "3 星半 。 1 . 电影 结束 有 掌声 出现 ， 近期 少见 。 2 . 一粒 爱国主义 大补丸 ， 有人 吃 的 开心 ， 有人 觉得 补大 了 。 3 . 从头 打到 尾 ， 从白 打到 黑 。 4 . 从 片头 字幕 到 影片 细节 ， 完全 展现 了 吴京 作为 一个 超级 直 男 的 糙 和 猛 。 主角 光环 媲美 终结者 。 5 . 达康 书记 无亮点 ， 张翰变 谐星 。 6.3 D ？ ？ ？ 7 . 导演 的 掌控 能力 逼近 Hold 不住 的 边缘 。\n",
      "打戏 非常 带感 ， 燃爆 了 ， 拳拳 到 肉 ， 看 得 超爽 ！\n",
      "吴京 确实 很 聪明 ， 很 鸡 贼 。 在 一面 大 旗下 呈现 了 一出 重工业 娱乐 电影 。 他 一直 调控 着 说教 和 娱乐 的 比例 ， 娱乐 多 了 ， 尺度 不 被 允许 ， 说教 多 了 ， 大众 不 接纳 ， 比例 把握 非常 微妙 。 这 其中 还是 有 一些 “ 奇侠 ” 化 的 内容 ， 比如 用 玻璃碴 子当 飞镖 杀敌 一类 ， 只不过 被 遮盖 掉 了 。 “ 老爹 ” 演过 美剧 《 搏击 王国 》 ， 力荐 那部 美剧\n",
      "作为 主旋律 影片 为啥 用 《 奇异 恩典 》 配乐 ， 画内 镜头 还是 中国 军人 … …\n",
      "男生 看 这部 电影 的话 ， 应该 会 很 喜欢 ， 因为 很 刺激 肾上腺素 ， 如果 是 女生 ， 冷锋 对龙小云 的 感情 也 会 十分 打动 你 ， 真的 ！\n",
      "无脑 动作片 ， 模仿 许多 好莱坞 大 场面 再 想 怎么 玩 怎么 玩 一股脑 堆 ， 槽 点 多 到 炸 ， 几位 主角 血厚到 科幻 级别 ， 吴京 重复 演 满血 ， 红血 ， 中毒 ， 极速 回血 ， 爆种 打通 全场 ... 确实 很 拼 但 片子 太过 投机取巧 ， 炸 穿 银幕 连 迈克尔 贝都 不受 待见 了 ， 国片 还 前仆后继 炸 不停 ， 故事 不 好看 堆 再 多 大 场面 大 爆炸 假 high 瞎燃 也 没用 。 5 / 10\n",
      "吴京 ： 这种 女人 就 缺 我 这样 的 男人 征服 。 心往 一处 想 ， 劲往 一处 使 ， 就 能 实现 吴京直 男癌 的 中国 梦 🇨 🇳\n",
      "美国 大片 就 能 意淫 ， 国产 的 就 不行 ？ 美国 的 就 打 不 死 ， 全都 跳 飞机 跟 跳墙 一样 ， 中国 就 不行 ？\n",
      "好莱坞 总是 美国 总是 拯救 世界 ， 国产片 就是 中国 梦想 拯救 非洲\n",
      "以 现在 的 中印 局势 ， 来 对比 这部 电影 假想 的 内容 ， 还 真是 挺 讽刺 的 哈哈哈\n",
      "谄媚 投机 到 恶心 。\n",
      "作为 军旅 题材 给 四星 我 觉得 不过 分 ， 质感 燃到 爆炸\n",
      "燃 ！ 大 场面 真的 不输 国外 大片 不 尴尬 ， 吴京 打戏 很 精彩 ， 水下 搏斗 看着 也 很 有力 ， 必须 安利 一下张 翰 ， 这 角色 简直 就是 个 彩蛋 啊 ， 承包 所有 笑点 ， 为 他 量身定做 的 哈哈哈 ， 彭于 晏 可演 不来 。 是 真的 好看\n",
      "《 战狼 2 》 的 制作 明显 比 第一部 升级 了 不少 ， 坦克 漂移 、 无人机 突袭 、 直升机 坠露 、 水下 肉搏 ， 军舰 导弹 发射 、 场面 和 动作 再 加上 非洲 叛乱 国际化 的 视角 完全 是 好莱坞 大片 的 标配 ， 吴京 饰演 的 冷锋 更加 深入人心 ， 如此 搏命 的 精神 在 当下 华语 动作 电影 算是 少见 了 ， 期待 第三部 。\n",
      "好燃 啊 ！ 好看 ！ 表白 吴京 和 达康 书记 ！\n",
      "燃 ！ 大 场面 真的 不输 国外 大片 不 尴尬 ， 吴京 打戏 很 精彩 ， 水下 搏斗 看着 也 很 有力 ， 必须 安利 一下张 翰 ， 这 角色 简直 就是 个 彩蛋 啊 ， 承包 所有 笑点 ， 为 他 量身定做 的 哈哈哈 ， 彭于 晏 可演 不来 。 是 真的 好看\n",
      "《 战狼 2 》 的 制作 明显 比 第一部 升级 了 不少 ， 坦克 漂移 、 无人机 突袭 、 直升机 坠露 、 水下 肉搏 ， 军舰 导弹 发射 、 场面 和 动作 再 加上 非洲 叛乱 国际化 的 视角 完全 是 好莱坞 大片 的 标配 ， 吴京 饰演 的 冷锋 更加 深入人心 ， 如此 搏命 的 精神 在 当下 华语 动作 电影 算是 少见 了 ， 期待 第三部 。\n",
      "好燃 啊 ！ 好看 ！ 表白 吴京 和 达康 书记 ！\n",
      "典型 美国 大片 的 方式 ， 每次 都 能 猜 对 剧情 ， 没劲 诶 ~ 我 就 想 问 ， 王牌 特工 就 那么 点 杀人 的 镜头 ， 还 经过 艺术 处理 ， 都 直接 删 了 ， 战狼 2 这种 血腥 屠杀 的 镜头 ， 赤裸裸 的 ， 大段 大段 的 ， 是 怎么 过 的 ？ 政治 正确 就 有 庇衣 了 ？\n",
      "意料之中 的 精彩 ， 意料之外 的 惊喜 。 属于 我们 的 英雄 ， 展现 狼性 的 军魂 。\n",
      "几个 网红拉 出来 弹弹琴 你们 就 说 燃 了 ？ 彰显 我 大国 气象 荷尔蒙 满屏 ， 这 TM 才 叫 燃 ！ ！ ！ 这部 电影 告诉 我们 中国 人 也 是 可以 拯救 世界 的 ！\n",
      "吴 迪塞尔 如入无人之境 ， 7 亿 大陆 直 男 在 这 一刻 集体 勃起 。 心往 一处 想 ， 劲往 一处 使 ， 你 就 能 离开 影厅 不是 个 屌丝 了 ？\n",
      "同样 是 主旋律 ， 片子 比 电影 开始 前 的 《 我 的 中国 梦 》 要 屌 一万倍 。\n",
      "吴京 这 一次 完全 就是 用 超级 英雄 的 标准 来 打造 角色 ， 美式 英雄主义 与 主旋律 的 违 和 是 不可逆转 的 缺点 ， 各种 笑料 也 一定 程度 地 破坏 了 节奏感 ； 斥 巨资 炮制 的 大 场面 有所 体验 ， 动作 场面 的 流畅 自然 也 比得上 好莱坞 水准 ， 但 满到 溢出 却 又 影响 了 观感 。 有着 明显 的 优缺点 ， 但 却 会 是 受 一般 观众 喜爱 的 院线 电影 。 两星 半 。\n",
      "3d 扣分\n",
      "和 第一部 同样 精彩 ， 看 完 之后 我 热血 澎拜 啊\n",
      "纯粹 拍 的 很 难看 啊 … …\n",
      "集体 癔症 。\n",
      "这个 系列 从 1 开始 就 跟 吃 了 壮阳药 似的 。\n",
      "张翰脸 比 女主白 太多 了 ， 请问 用 了 什么 护肤品 ？ ！\n",
      "客观 的 说 七分 ， 虽然 情节 逻辑 有 各种 经不起 推敲 的 细节 ， 但 总体 完成度 很 高 ， 虽然 反派 有点 无脑 脸谱化 ， 但 配角 形象 还 算 丰满 ， 尤其 张瀚 的 富 二代 形象 居然 不招 人 讨厌 。 有 笑 点 有 泪点 ， 是 部 用心 的 片子 ， 瑕不掩瑜 ， 值得 鼓励 。\n",
      "在 吴京 的 个人 英雄 幻想 下 连 主旋律 都 沦为 附庸 了 ， 我 tm 还 能 说 什么 ... 主角 已经 牛逼到 突破 逻辑 的 地步 ！ 全 天下 超级 无敌 牛 逼 就是 你 了 好 啦 好 啦 我 都 知道\n",
      "1 . 看看 人家 装逼装 得 多 专业 。 2 . 由于 全国 发布 高温 警报 ， 主角 只好 去 非洲 避暑 了 。 3 . Tundu ： 我 不要 去 中国 ， 中国 太 他 妈 热 了 ， 我会 被 晒黑 的 ！ 4 . 张翰 在 本片 饰演 亦 凡 ， 整个 太平洋 都 是 他 承包 的 鱼塘 。 5 . 达康 书记 、 东来 局长 都 是 幌子 ， 实际上 反派 是 美队 对 冷锋 的 考验 ， 下集 他 将 加入 复联 一起 打灭 霸 。\n",
      "三星 半 ， 与 首部 一脉相承 ， 但 脱离 了 军旅 题材 的 限制 ， 变成 了 孤胆 英雄 动作片 ， 与 第一 滴血 系列 是 一样 的 ， 故事 不 新鲜 ， 但 场面 更大 ， 动作 部分 在 技巧 / 火爆 之间 切换 ， 整体 非常 燃 ， 片长 有些 长 。 能 看出 拍摄 时 受限 颇 多 ， 有 的 镜头 一看 就是 硬性 指标 ， 但 这样 的 片 对 拓展 华语 类型 片有 好处 ， 还是 多多益善\n",
      "已三刷 。 不 明白 为什么 会 有人 说 中 二 和 吴京 意淫 。 这种 类型 的 电影 肯定 要 有 一个 英雄人物 带动 情节 的 发展 。 真的 好看 ， 全场 无尿点 。 谁 会 希望 有 战乱 ， 一些 人 或 群体 为了 自己 的 私人 利益 ， 发动战争 ， 但 这苦 的 可是 手无寸铁 之力 的 民众 ， 祈求 一个 永远 也 实现 不了 的 愿望 ： 世界 和平 。 黑子 跪久 了 都 站不起来 了 ， 5 分 力荐 ！\n",
      "张翰脸 比 女主白 太多 了 ， 请问 用 了 什么 护肤品 ？ ！\n",
      "客观 的 说 七分 ， 虽然 情节 逻辑 有 各种 经不起 推敲 的 细节 ， 但 总体 完成度 很 高 ， 虽然 反派 有点 无脑 脸谱化 ， 但 配角 形象 还 算 丰满 ， 尤其 张瀚 的 富 二代 形象 居然 不招 人 讨厌 。 有 笑 点 有 泪点 ， 是 部 用心 的 片子 ， 瑕不掩瑜 ， 值得 鼓励 。\n",
      "在 吴京 的 个人 英雄 幻想 下 连 主旋律 都 沦为 附庸 了 ， 我 tm 还 能 说 什么 ... 主角 已经 牛逼到 突破 逻辑 的 地步 ！ 全 天下 超级 无敌 牛 逼 就是 你 了 好 啦 好 啦 我 都 知道\n",
      "1 . 看看 人家 装逼装 得 多 专业 。 2 . 由于 全国 发布 高温 警报 ， 主角 只好 去 非洲 避暑 了 。 3 . Tundu ： 我 不要 去 中国 ， 中国 太 他 妈 热 了 ， 我会 被 晒黑 的 ！ 4 . 张翰 在 本片 饰演 亦 凡 ， 整个 太平洋 都 是 他 承包 的 鱼塘 。 5 . 达康 书记 、 东来 局长 都 是 幌子 ， 实际上 反派 是 美队 对 冷锋 的 考验 ， 下集 他 将 加入 复联 一起 打灭 霸 。\n",
      "三星 半 ， 与 首部 一脉相承 ， 但 脱离 了 军旅 题材 的 限制 ， 变成 了 孤胆 英雄 动作片 ， 与 第一 滴血 系列 是 一样 的 ， 故事 不 新鲜 ， 但 场面 更大 ， 动作 部分 在 技巧 / 火爆 之间 切换 ， 整体 非常 燃 ， 片长 有些 长 。 能 看出 拍摄 时 受限 颇 多 ， 有 的 镜头 一看 就是 硬性 指标 ， 但 这样 的 片 对 拓展 华语 类型 片有 好处 ， 还是 多多益善\n",
      "已三刷 。 不 明白 为什么 会 有人 说 中 二 和 吴京 意淫 。 这种 类型 的 电影 肯定 要 有 一个 英雄人物 带动 情节 的 发展 。 真的 好看 ， 全场 无尿点 。 谁 会 希望 有 战乱 ， 一些 人 或 群体 为了 自己 的 私人 利益 ， 发动战争 ， 但 这苦 的 可是 手无寸铁 之力 的 民众 ， 祈求 一个 永远 也 实现 不了 的 愿望 ： 世界 和平 。 黑子 跪久 了 都 站不起来 了 ， 5 分 力荐 ！\n",
      "样板戏 走向 全球\n",
      "捧 高 美国 队长 ， 贬低 战狼 ， 双重标准 不要 玩 的 太 溜 … … 好莱坞 玩爱 美国 就是 高大 上 ， 国内 玩 爱国 就是 假大空 ， 真 不 懂 你们 这些 没有 膝盖 的 人\n",
      "二十年 前 ， 当 我 还是 个 懵懂 的 小孩子 ， 看到 这样 的 故事 和 镜头 ， 我会 被 感动 的 哭鼻子 ； 如今 ， 二十年 过去 了 ， 你 却 还 拿 这样 的 故事 逻辑 和 镜头 给 我 看 ， 我 只能 尴尬 的 笑 。\n",
      "《 战狼 2 》 可以 说用 军舰 坦克 ， 撞开 了 国产电影 重工业 的 大门 。 让 观众 了解 到 国产电影 也 可以 像 好莱坞 大片 一样 ， 可以 有 自己 的 超级 英雄 。\n",
      "说 剧情 有 bug ， 我 承认 。 但 你 看 的 燃不燃 ？ high 不 high ？ 动作 打 得 过瘾 不 过瘾 ？ 看 得 心潮澎湃 没有 ？ 激动 不 ？ 国产 商业 动作片 能 拍 到 这个 水准 ， 已经 值得 表扬 了 。 不 给 鼓励 还 在 那 挑刺 ？ 呵呵 。\n",
      "这一星 给 开场 拆 房子 的 那场 戏 ， 太 不 符合 社会主义 核心 价值观 了 ！\n",
      "# 电影院 # 一个 人 就 买 了 四张 票 （ 不 打折 ） 请 全家 看 ， 心疼 我 的 小钱 钱 ≥ ﹏ ≤   还好 家长 们 的 反应 是 好 的 ， 把 吴京 猛 夸 了 一通 ， 中国式 的 动作 大片 并 不 逊色 好莱坞 ， 只要 他们 满意 我 也 就 心满意足 了 。 我 珍惜 一家人 和和气气 的 团聚 时刻 。 卢靖姗真 漂亮 ， 干练 明朗 的 健康美 。 吴京 好好 拍 ， 第三部 继续 约 啊\n",
      "听说 过 夜郎自大 吗 ？ 我 第一次 知道 中国 人 这么 牛 逼 。 中国 部队 所向披靡 ， 连特 么 坦克 都 能 给 你 开 漂移 。 整部 电影 都 是 吴京 一个 人 在 意淫 。 意淫 真 可怕 ， 中国 维和 单凭 一个 视频 能 越过 联合国 长驱直入 到 别国 领土 进行 作战 。 你 当 Africa 是 你家 后院 么 ？ 意淫 强国 ， 我 身为 天朝 子民 相当 之 荣幸 。 扬 我国 威 ， 震 我 中华 ！\n",
      "我 跟 你们 讲 ， 吴京 当年 在 电视 上大 吹牛 逼 ， 说 自己 在 杀 破 狼 里 和 甄子丹 真打 ， 多 厉害 多牛 逼 。 结果 花絮 里 明明白白 地 展现 了 甄 如何 设计 全套 动作 ， 从头到尾 手把手 地教 吴京 。\n",
      "「 中國 狼 不 咬 中國人 ！ 」 www\n",
      "冷锋 像是 一个 符号 ， 他 代表 着 千千万万 守护 我们 的 军人 。 “ 国强 则 民安 ” ， 生活 在 这个 没有 战争 的 国度 ， 我们 真的 算是 非常 幸福 。 每 一个 军人 都 值得 我们 尊敬 ， 这个 强大 的 祖国 也 值得 我们 热爱 。 如同 影片 的 主旨 ： “ 中国 护照 不能 带你去 任何 一个 国家 ， 但 能 从 任何 一个 地方 把 你 平安 带回家 。 ”\n",
      "非常 难看   也 不 知道 导演 哪儿 来 的 自信\n",
      "一部 政治 宣传片 ！ 中国 也 就 在 非洲 还 有点 脸面 了 ！ 给 宏大 的 战争场面 和 吴京 卖力 的 打斗 五星 ， 剧情 减一星 ， 政治 倾向 剪一星 ， 综合 三星 ！\n",
      "诚意 满满 ， 全程无 尿点 。 吴京 非常 帅 ， 剧情 比战 狼 1 好看 多 了 。\n",
      "23 点 45 分 开始 ， 1 点 48 分 结束 ， 我 看 了 12 次 手机 ， 影厅 的 天花板 上 有 8 条线 组合成 三角形 装饰 ， 18 个 音响 在 棚顶 前 12 个 并列 排放 ， 后面 6 个 33 一组 ， 一共 24 个 探照灯 ， 第 12 个 旁边 有个 摄像头 。 另外 ， 中国 护照 上 没有 那句话 。\n",
      "有 一场 坦克 戏 ， 简直 令人 浮想 连连 啊 ， 吴京 真的 不是故意 的 嘛 。 又 是 压人压 成肉 泥 的 镜头 ， 又 是 吴京站 在 坦克 正 前面 ， “ 稍 有 常识 的 人 都 会 看出 ， 如果 敌方 的 铁骑 继续前进 ” ， 然而 吴京 这个 螳臂当车 的 歹徒 真的 阻挡 住 了 。\n"
     ]
    }
   ],
   "source": [
    "# 豆瓣评论数据集\n",
    "def read_comment_csv(filename):\n",
    "    content = pd.read_csv(filename, encoding='UTF-8', low_memory=False).astype(str)\n",
    "    comment = content['comment'].tolist()\n",
    "    for (j, l) in enumerate(comment):\n",
    "        u = jieba.lcut(l)\n",
    "        da = ' '.join(u)\n",
    "        comment[j] = da\n",
    "    return comment\n",
    "\n",
    "\n",
    "comment = read_comment_csv('movie_comments.csv')\n",
    "print(type(comment))\n",
    "for i in range(100):\n",
    "    print(comment[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12889\n",
      "  法律 要求 残疾 保险 吗 ？  \n",
      "  债权人 可以 在 死 后 人寿保险 吗 ？  \n",
      "  旅行者 保险 有 租赁 保险 吗 ？  \n",
      "  我 可以 开 一辆 没有 保险 的 新车 吗 ？  \n",
      "  人寿保险 的 现金 转 出 价值 是否 应 纳税 ？  \n",
      "  如何 报告 年 金 收入 ？  \n",
      "  AAA 家庭 保险 涵盖 什么 ？  \n",
      "  什么 是 简单 的 退休 计划 ？  \n",
      "  社会保险 残疾 保险 是 什么 ？  \n",
      "  汽车保险 是否 预付 ？  \n",
      "  医疗保险 B 部分 盖 什么 ？  \n",
      "  退伍军人 能否 获得 人寿保险 ？  \n",
      "  我 的 房主 保险 是否 包括 失去 的 结婚戒指 ？  \n",
      "  分配 风险 汽车保险 如何 工作 ？  \n",
      "  我 的 男朋友 可以 加 我 的 汽车保险 吗 ？  \n",
      "  我 是否 需要 提交 私人 财产 车祸 索赔 的 警察 报告 ？  \n",
      "  全 覆盖 汽车保险 盖 修理 ？  \n",
      "  人生 在 伊斯兰教 中 是否 可以 接受 ？  \n",
      "  健康 保险 是否 覆盖 管道 逆转 ？  \n",
      "  如果 您 已经 诊断 为 乳腺癌 ， 您 可以 获得 多大 的 人寿保险 ？  \n",
      "  我 需要 注册 医疗保险 ？  \n",
      "  短期 残疾 保险 是否 工作 ？  \n",
      "  房主 保险 盖池 ？  \n",
      "  什么 时候 要 注册 医疗保险 ？  \n",
      "  MIP 会 影响 我 的 汽车保险 吗 ？  \n",
      "  蓝 十字 蓝盾 有 人寿保险 吗 ？  \n",
      "  长期 护理 保险 的 优点 和 缺点 是 什么 ？  \n",
      "  医疗保险 支付 生命 预警 ？  \n",
      "  我 应该 买 哪种 人寿 ？  \n",
      "  医疗保险 支付 HPV 筛查 吗 ？  \n",
      "  哪个 是 最好 的 人寿保险 ？  \n",
      "  长期 护理 保险费用 多少 ？  \n",
      "  固定 年 金 如何 安全 ？  \n",
      "  要 解决 人寿保险 索赔 需要 多长时间 ？  \n",
      "  是否 检查 汽车保险 信贷 ？  \n",
      "  我 可以 使用 HSA 支付 长期 护理 保险 吗 ？  \n",
      "  雇主 可以 向 吸烟者 收取 更 多 健康 保险费 吗 ？  \n",
      "  房屋 所有权 保险 通常 覆盖 什么 ？  \n",
      "  没有 健康 保险 的 超声波 成本 是 多少 ？  \n",
      "  什么 是 10 年期 人寿保险 ？  \n",
      "  你 可以 把 钱 放在 一个 401K 和 一个 Roth   IRA ？  \n",
      "  我 可以 用 丙型肝炎 保险 吗 ？  \n",
      "  什么 时候 可以 注册 医疗保险 A 部分 ？  \n",
      "  健康 保险 何时 起源 ？  \n",
      "  医疗保险 有 多 重要 ？  \n",
      "  租用 保险费用 多少 ？  \n",
      "  我 的 家庭 保险 是否 覆盖 盗窃 ？  \n",
      "  租户 保险 如何 受益 业主 ？  \n",
      "  俄亥俄州 雇主 是否 必须 提供 健康 保险 ？  \n",
      "  我 应该 有 多少 汽车保险 ？  \n",
      "  为什么 房主 保险 增加 ？  \n",
      "  谁 能 买 医保 ？  \n",
      "  如何 清除 Medicare   B 部分 ？  \n",
      "  在 什么 年龄 我 应该 得到 长期 护理 保险 ？  \n",
      "  人寿保险 死亡 福利 是否 应 纳税 ？  \n",
      "  什么 是 医疗 储蓄 计划 ？  \n",
      "  房主 保险 是否 向 其他 狗盖 狗 叮咬 ？  \n",
      "  医疗保险 计划 盖 什么 ？  \n",
      "  全 人寿保险 是 一个 好 的 选择 吗 ？  \n",
      "  雇主 可以 提供 不同 数额 的 健康 保险 吗 ？  \n",
      "  将来 会 发生 什么 医疗保险 ？  \n",
      "  一般 人寿保险 ？  \n",
      "  我 的 汽车保险 是否 会 如果 得到 机票 呢 ？  \n",
      "  租客 保险 是否 包括 盗窃 ？  \n",
      "  什么 是 租赁 保险 ？  \n",
      "  如何 计算 家庭 保险 ？  \n",
      "  房主 保险 是否 覆盖 下水道 维修 ？  \n",
      "  AARP 是否 有 长期 护理 保险 ？  \n",
      "  短期 残疾 考虑 健康 保险 吗 ？  \n",
      "  在 什么 年龄 你 应该 得到 人寿保险 ？  \n",
      "  旅行者 家庭 保险 好 吗 ？  \n",
      "  谁 能 得到 医疗保险 ？  \n",
      "  谁 有 最 优惠 的 租金 保险费率 ？  \n",
      "  谁 能 驾驶 你 的 车 在 你 的 保险 ？  \n",
      "  医疗保险 可以 支付 养老院 吗 ？  \n",
      "  如果 汽车保险 失败 ， 会 发生 什么 ？  \n",
      "  车库 门 由 房主 保险 覆盖 ？  \n",
      "  我 在 哪里 注册 医疗保险 ？  \n",
      "  如何 获得 汽车保险 最佳 交易 ？  \n",
      "  在 新泽西州 如何 申请 Medicare   Part   D ？  \n",
      "  哪家 公司 提供 最佳 租赁 保险 ？  \n",
      "  全 人寿保险 有 哪些 特点 ？  \n",
      "  什么 是 年 金种 现金流 ？  \n",
      "  可以 在 乳腺癌 后 获得 人身保险 吗 ？  \n",
      "  如何 找出 多少 汽车保险 呢 ？  \n",
      "  如何 计划 退休 与 401K ？  \n",
      "  什么 是 不 符合 奥巴马 的 健康 保险 的 税收 减免 ？  \n",
      "  你 能 失去 医疗 福利 吗 ？  \n",
      "  房主 保险 是否 会 损失 钻石 ？  \n",
      "  长期 护理 保险费用 多少 ？  \n",
      "  何时 应该 停止 支付 人寿保险 ？  \n",
      "  你 去 医疗保险 什么 年龄 ？  \n",
      "  人寿保险 公司 如何 吸烟 ？  \n",
      "  如何 确定 您 是否 需要 长期 护理 保险 ？  \n",
      "  谁 制造 汽车保险 ？  \n",
      "  什么 时候 应该 得到 期限 人寿保险 ？  \n",
      "  信用 与 汽车保险 有 什么 关系 ？  \n",
      "  家庭 保险 是否 支付 屋顶 更换 ？  \n",
      "  谁 拥有 最好 和 最 便宜 的 汽车保险 ？  \n",
      "  你 能 租 汽车保险 吗 ？  \n"
     ]
    }
   ],
   "source": [
    "# 保险行业问询对话集\n",
    "def read_txt(filename):\n",
    "    with open(filename, \"r\", encoding='UTF-8') as f:\n",
    "        lines = f.readlines()\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        chinese = line.split('++$++')[2]\n",
    "        data.append(chinese)\n",
    "    for (i, da) in enumerate(data):\n",
    "        u = jieba.lcut(da)\n",
    "        da = ' '.join(u)\n",
    "        data[i] = da\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "data = read_txt('train.txt')\n",
    "for i in range(100):\n",
    "    print(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut(string): return list(jieba.lcut(string))\n",
    "def prob_2(word1, word2):  # p(w1,w2) = count(w1,2)/count(w1)\n",
    "    if word1 + word2 in words_count_2: return words_count_2[word1+word2] / words_count[word1]\n",
    "    else:\n",
    "        return 1 / len(TOKEN_2_GRAM)\n",
    "def get_probablity(sentence):\n",
    "    words = cut(sentence)\n",
    "    \n",
    "    sentence_pro = 1\n",
    "    \n",
    "    for i, word in enumerate(words[:-1]):\n",
    "        next_ = words[i+1]\n",
    "        \n",
    "        probability = prob_2(word, next_)  # p(w1|w2)\n",
    "        \n",
    "        sentence_pro *= probability  # p(s) = p(w_1)p(w2|w1)*p(w3|w2)..p(wn|wn-1) \n",
    "    \n",
    "    return sentence_pro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "# data 和 comment\n",
    "TOKEN = []\n",
    "\n",
    "\n",
    "def construct_dataset(dataset, TOKEN):\n",
    "    for i in range(len(dataset)):\n",
    "        if i % 100 == 0: print(i)\n",
    "        if i > 20000: break   \n",
    "        TOKEN += dataset[i].split()\n",
    "    return TOKEN\n",
    "\n",
    "\n",
    "TOKEN = construct_dataset(data, TOKEN)\n",
    "TOKEN = construct_dataset(comment, TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = Counter(TOKEN)\n",
    "TOKEN = [str(t) for t in TOKEN]\n",
    "TOKEN_2_GRAM = [''.join(TOKEN[i:i+2]) for i in range(len(TOKEN[:-2]))]\n",
    "words_count_2 = Counter(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie:\n",
      "句子1的概率： 3.341319549865117e-57\n",
      "句子2的概率： 1.961837879911964e-49\n",
      "句子3的概率： 1.498823889773713e-47\n",
      "句子4的概率： 9.085369325633126e-38\n",
      "句子5的概率： 1.8411953275839408e-40\n",
      "句子6的概率： 9.205136306903115e-59\n",
      "句子7的概率： 2.9472109355703047e-44\n",
      "句子8的概率： 1.1515717542204464e-52\n",
      "句子9的概率： 5.671460124456292e-45\n",
      "句子10的概率： 1.141507855905716e-53\n",
      "句子11的概率： 4.032319546961316e-44\n",
      "句子12的概率： 2.049209496631146e-52\n",
      "句子13的概率： 1.371448783262283e-48\n",
      "句子14的概率： 2.4754917679702312e-51\n",
      "句子15的概率： 1.2172069630665554e-61\n",
      "句子16的概率： 8.492773361586369e-56\n",
      "句子17的概率： 1.5243605220741005e-45\n",
      "句子18的概率： 1.546560133585071e-40\n",
      "句子19的概率： 8.264128322900198e-60\n",
      "句子20的概率： 9.518392934946786e-51\n",
      "daily life:\n",
      "句子1的概率： 1.192547571915233e-55\n",
      "句子2的概率： 4.086691347844392e-26\n",
      "句子3的概率： 6.334503636062101e-48\n",
      "句子4的概率： 3.0925573934551854e-41\n",
      "句子5的概率： 1.761829941493252e-39\n",
      "句子6的概率： 1.993039068784315e-53\n",
      "句子7的概率： 1.75005530940457e-49\n",
      "句子8的概率： 4.869503143657138e-41\n",
      "句子9的概率： 1.1477032092021144e-40\n",
      "句子10的概率： 4.9675256570952034e-51\n",
      "句子11的概率： 8.057653397383517e-40\n",
      "句子12的概率： 5.0401961904029844e-48\n",
      "句子13的概率： 3.2819599914434125e-47\n",
      "句子14的概率： 5.593185374761067e-43\n",
      "句子15的概率： 7.914377932662252e-40\n",
      "句子16的概率： 8.676157444453749e-48\n",
      "句子17的概率： 1.2062184524759327e-38\n",
      "句子18的概率： 4.2923174788202314e-39\n",
      "句子19的概率： 4.1456680884008395e-39\n",
      "句子20的概率： 2.1332000761202764e-53\n"
     ]
    }
   ],
   "source": [
    "movie_sentence = generate_n(movie, 'sentence', 20)\n",
    "daily_life_sentence = generate_n(daily_life, 'sentence', 20)\n",
    "print('movie:')\n",
    "for i in range(20):\n",
    "    prob = get_probablity(movie_sentence[i])\n",
    "    print('句子{}的概率： {}'.format(i+1, prob))\n",
    "print('daily life:')\n",
    "for i in range(20):\n",
    "    prob = get_probablity(daily_life_sentence[i])\n",
    "    print('句子{}的概率： {}'.format(i+1, prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点** 1. 是否使用了新的数据集； 2. csv(txt)数据是否正确解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([1, 3, 5, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数接受一个参数key，这个参数接受一个函数作为输入，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 5), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第0个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0), (1, 4), (4, 4), (2, 5)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (1, 4), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序, 但是是递减的顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "《三傻大闹宝莱坞》是中国电影，他不喜欢这部电影，但是看过了， 2.772448769141349e-28\n",
      "弟弟。今天天气很好，我们去电影吧。 2.6745243418266294e-27\n"
     ]
    }
   ],
   "source": [
    "def generate_best(gram, target, n): \n",
    "    # 随机生成n个句子\n",
    "    sentence_list = []\n",
    "    for i in range(n):\n",
    "        if target not in gram: return target \n",
    "    \n",
    "        expaned = [generate(gram, t) for t in choice(gram[target])]  \n",
    "        sentence = ''.join([e if e != '/n' else '\\n' for e in expaned if e != 'null']) \n",
    "        sentence_list.append(sentence)\n",
    "    prob_list = []\n",
    "    for s in sentence_list:\n",
    "        prob = get_probablity(s)\n",
    "        prob_list.append(prob)\n",
    "    s_prob_list = []\n",
    "    for i in range(n):\n",
    "        s_prob_list.append((i, prob_list[i]))\n",
    "    s_prob_list = sorted(s_prob_list, key=lambda x: x[1], reverse=True)\n",
    "    # 根据概率找到最合理的句子   \n",
    "    best = s_prob_list[0][0]\n",
    "    return sentence_list[best], s_prob_list[0][1]\n",
    "\n",
    "\n",
    "sentence1, prob1 = generate_best(movie, 'sentence', 1000)\n",
    "sentence2, prob2 = generate_best(daily_life, 'sentence', 1000)\n",
    "print(sentence1, prob1)\n",
    "print(sentence2, prob2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **评阅点**： 是否使用 lambda 语法进行排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:数据方面不是很全面，提升需要增加更多不同领域的句子或对话描述，以扩增数据集包含到领域。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**评阅点**: 是否提出了比较实际的问题，例如OOV问题，例如数据量，例如变成 3-gram问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 另外一份作业文件里有个optional，有兴趣的同学可以挑战一下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，我们已经完成了自己的第一个AI模型，大家对人工智能可能已经有了一些感觉，人工智能的核心就是，我们如何设计一个模型、程序，在外部的输入变化的时候，我们的程序不变，依然能够解决问题。人工智能是一个很大的领域，目前大家所熟知的深度学习只是其中一小部分，之后也肯定会有更多的方法提出来，但是大家知道人工智能的目标，就知道了之后进步的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，希望大家对AI不要有恐惧感，这个并不难，大家加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
